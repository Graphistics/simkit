{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5a9c17",
   "metadata": {},
   "source": [
    "# Custom Spectral Clustering with Iris Dataset\n",
    "\n",
    "This notebook defines a custom spectral clustering function that supports:\n",
    "- **Similarity graph**: \"full\", \"eps\", \"knn\", or \"mknn\"\n",
    "- **Laplacian**: \"sym\" (symmetric) or \"rw\" (random walk)\n",
    "\n",
    "It then loads the Iris dataset (from `datasets/iris.csv`) and applies our custom clustering approach, finishing with KMeans from scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aa8176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist, squareform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d7348c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(matrix, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Returns True if 'matrix' is symmetric within a given tolerance.\n",
    "    \"\"\"\n",
    "    return np.allclose(matrix, matrix.T, atol=tol)\n",
    "\n",
    "def spectral_clustering(dataframe, similarity_graph, laplacian, number_of_clusters, eps=None, k=None):\n",
    "    \"\"\"\n",
    "    Custom spectral clustering function that:\n",
    "      - Builds 'full', 'eps', 'knn', or 'mknn' adjacency graph\n",
    "      - Uses either 'sym' (symmetric) or 'rw' (random walk) Laplacian\n",
    "      - Finds eigen-decomposition (eigh if symmetric, else eig)\n",
    "      - Clusters the final eigenvectors with KMeans\n",
    "      - Returns (k, cluster_labels, silhouette)\n",
    "\n",
    "    'eig' vs. 'eigh' depends on matrix symmetry, as requested.\n",
    "    \"\"\"\n",
    "    # Pairwise distances\n",
    "    dimension = dataframe.shape[0]\n",
    "    dist_mat = squareform(pdist(dataframe))\n",
    "\n",
    "    sample_size = len(dist_mat)\n",
    "    \n",
    "    # Set n based on proportional selection, but limit by log scaling for large datasets\n",
    "    n = min(sample_size // 10, int(math.log(sample_size)))\n",
    "\n",
    "    # Fallback values for epsilon and k\n",
    "    epsilon = eps if eps else np.percentile(dist_mat, 90)\n",
    "    k = k if k else int(np.sqrt(sample_size))\n",
    "    \n",
    "    if similarity_graph == \"full\":\n",
    "\n",
    "        # Calculate local sigma\n",
    "        sigmas = np.zeros(dimension)\n",
    "        for i in tqdm(range(len(dist_mat)), desc=\"Local sigma\"):\n",
    "            sigmas[i] = sorted(dist_mat[i])[n]\n",
    "\n",
    "        # Adjacency matrix with local sigmas\n",
    "        adjacency_matrix = np.zeros((dimension, dimension))\n",
    "        for i in tqdm(range(dimension), desc=\"Building Full Graph\"):\n",
    "            for j in range(i+1, dimension):\n",
    "                d = np.exp(-1 * dist_mat[i,j]**2 / (sigmas[i] * sigmas[j]))\n",
    "                adjacency_matrix[i,j] = d\n",
    "                adjacency_matrix[j,i] = d\n",
    "\n",
    "    elif similarity_graph == \"eps\":\n",
    "\n",
    "        # Adjacency matrix with epsilon threshold\n",
    "        adjacency_matrix = np.zeros((dimension, dimension))\n",
    "        for i in tqdm(range(dimension), desc=\"Building Eps Graph\"):\n",
    "            for j in range(i+1, dimension):\n",
    "                if dist_mat[i,j] < epsilon:\n",
    "                    adjacency_matrix[i,j] = 1\n",
    "                    adjacency_matrix[j,i] = 1\n",
    "\n",
    "    elif similarity_graph == \"knn\":\n",
    "        adjacency_matrix = np.zeros((dimension, dimension))\n",
    "        for i in tqdm(range(dimension), desc=\"Building kNN Graph\"):\n",
    "            sorted_indices = np.argsort(dist_mat[i])\n",
    "            k_nearest_indices = sorted_indices[1:k+1]  # Exclude itself\n",
    "            adjacency_matrix[i, k_nearest_indices] = 1\n",
    "\n",
    "    else:\n",
    "        # Mutual kNN\n",
    "        adjacency_matrix = np.zeros((dimension, dimension))\n",
    "        for i in tqdm(range(dimension), desc=\"Building m-kNN Graph\"):\n",
    "            sorted_indices = np.argsort(dist_mat[i])\n",
    "            k_nearest_indices = sorted_indices[1:k+1]\n",
    "            for neighbor in k_nearest_indices:\n",
    "                neighbor_sorted_indices = np.argsort(dist_mat[neighbor])\n",
    "                if i in neighbor_sorted_indices[1:k+1]:\n",
    "                    adjacency_matrix[i, neighbor] = 1\n",
    "                    adjacency_matrix[neighbor, i] = 1\n",
    "\n",
    "    # Degree matrix\n",
    "    degrees = adjacency_matrix.sum(axis=1)\n",
    "\n",
    "    # Build the chosen Laplacian\n",
    "    if laplacian == \"sym\":\n",
    "        d_inv_sqrt = np.zeros_like(degrees)\n",
    "        nonzero = degrees > 0\n",
    "        d_inv_sqrt[nonzero] = 1.0 / np.sqrt(degrees[nonzero])\n",
    "        D_half = np.diag(d_inv_sqrt)\n",
    "        laplacian_matrix_normalized = D_half @ adjacency_matrix @ D_half\n",
    "\n",
    "    elif laplacian == \"rw\":\n",
    "        d_inv = np.zeros_like(degrees)\n",
    "        nonzero = degrees > 0\n",
    "        d_inv[nonzero] = 1.0 / degrees[nonzero]\n",
    "        D_inverse = np.diag(d_inv)\n",
    "        laplacian_matrix_normalized = D_inverse @ adjacency_matrix\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported laplacian type. Only 'sym' and 'rw' are allowed.\")\n",
    "\n",
    "    # Choose eig or eigh\n",
    "    if check_symmetric(laplacian_matrix_normalized):\n",
    "        e, v = np.linalg.eigh(laplacian_matrix_normalized)\n",
    "    else:\n",
    "        e_complex, v_complex = np.linalg.eig(laplacian_matrix_normalized)\n",
    "        idx = np.argsort(np.real(e_complex))\n",
    "        e = np.real(e_complex[idx])\n",
    "        v = np.real(v_complex[:, idx])\n",
    "\n",
    "    # Eigengap (first 10 for safety)\n",
    "    eigengap = np.diff(e)\n",
    "    optimal_number_of_clusters = np.argmax(eigengap[:10]) + 1\n",
    "\n",
    "    # Decide number of clusters\n",
    "    if number_of_clusters == \"fixed2\":\n",
    "        current_k = 2\n",
    "    elif number_of_clusters == \"fixed3\":\n",
    "        current_k = 3\n",
    "    else:\n",
    "        current_k = max(optimal_number_of_clusters, 2)\n",
    "\n",
    "    # KMeans on the last current_k eigenvectors\n",
    "    X = v[:, -current_k:]\n",
    "    clustering = KMeans(n_clusters=current_k, random_state=42, n_init=100)\n",
    "    cluster_labels = clustering.fit_predict(X)\n",
    "\n",
    "    sil_score_val = silhouette_score(dataframe, cluster_labels) if current_k > 1 else None\n",
    "    return [(current_k, cluster_labels, sil_score_val)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ae5fc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local sigma: 100%|██████████| 150/150 [00:00<00:00, 45656.43it/s]\n",
      "Building Full Graph: 100%|██████████| 150/150 [00:00<00:00, 11905.04it/s]\n",
      "Local sigma: 100%|██████████| 150/150 [00:00<00:00, 38903.39it/s]\n",
      "Building Full Graph: 100%|██████████| 150/150 [00:00<00:00, 8256.40it/s]\n",
      "Building Eps Graph: 100%|██████████| 150/150 [00:00<00:00, 58319.02it/s]\n",
      "Building Eps Graph: 100%|██████████| 150/150 [00:00<00:00, 38028.63it/s]\n",
      "Building kNN Graph: 100%|██████████| 150/150 [00:00<00:00, 98906.71it/s]\n",
      "Building kNN Graph: 100%|██████████| 150/150 [00:00<00:00, 117246.66it/s]\n",
      "Building m-kNN Graph: 100%|██████████| 150/150 [00:00<00:00, 11934.17it/s]\n",
      "Building m-kNN Graph: 100%|██████████| 150/150 [00:00<00:00, 10680.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-combination results:\n",
      "   similarity_graph laplacian  k_found  silhouette_score\n",
      "0             full       sym        2          0.629885\n",
      "1             full        rw        2          0.629885\n",
      "2              eps       sym        2          0.629885\n",
      "3              eps        rw        2          0.286472\n",
      "4              knn       sym        7          0.320007\n",
      "5              knn        rw        7          0.320007\n",
      "6             mknn       sym        8          0.314433\n",
      "7             mknn        rw        8          0.329224 \n",
      "\n",
      "Average Silhouette across all combos: 0.4325\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset from 'datasets/iris.csv'\n",
    "df_iris = pd.read_csv(\"datasets/iris.csv\")\n",
    "\n",
    "# Optionally drop non-feature columns if present\n",
    "drop_cols = [col for col in [\"target\", \"Index\"] if col in df_iris.columns]\n",
    "df_iris = df_iris.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define all combinations of similarity_graph and Laplacian\n",
    "similarities = [\"full\", \"eps\", \"knn\", \"mknn\"]\n",
    "laplacians = [\"sym\", \"rw\"]\n",
    "\n",
    "all_results = []\n",
    "for sim in similarities:\n",
    "    for lap in laplacians:\n",
    "        # Call your spectral_clustering function\n",
    "        result = spectral_clustering(\n",
    "            dataframe=df_iris, \n",
    "            similarity_graph=sim, \n",
    "            laplacian=lap, \n",
    "            number_of_clusters=\"auto\"  # \"auto\" uses your eigengap approach\n",
    "        )\n",
    "        \n",
    "        # result is a list with one tuple: (k, cluster_labels, silhouette)\n",
    "        k_found, labels, sil = result[0]\n",
    "        \n",
    "        all_results.append({\n",
    "            \"similarity_graph\": sim,\n",
    "            \"laplacian\": lap,\n",
    "            \"k_found\": k_found,\n",
    "            \"silhouette_score\": sil\n",
    "        })\n",
    "\n",
    "# Create a DataFrame to display and analyze\n",
    "df_results = pd.DataFrame(all_results)\n",
    "print(\"Per-combination results:\\n\", df_results, \"\\n\")\n",
    "\n",
    "# Calculate average silhouette across all combinations\n",
    "avg_sil = df_results[\"silhouette_score\"].mean()\n",
    "print(f\"Average Silhouette across all combos: {avg_sil:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32debd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15635a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f09950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09114103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a9980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2738607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ff184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
